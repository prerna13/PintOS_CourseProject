    +--------------------+
      |        E0253       |
      | PROJECT 1: THREADS |
      |   DESIGN DOCUMENT  |
      +--------------------+
           
---- GROUP ----

MAYNAK GUPTA <mayankgupta@iisc.ac.in> sr No: 15165
PRERNA AROTE <prernaarote@iisc.ac.in> SR No: 15230 

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
  
>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.
https://tssurya.wordpress.com/2014/08/16/installing-pintos-on-your-machine/

           ALARM CLOCK
           ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

threads/thread.c:

1. static struct list sleeping_list; 
                List of all threads in sleeping state which would be woken up when the timer corresponding to them expires.

2. long long time_to_wake;
                Added a member in struct thread for Timer expire time for sleeping threads.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.
  
          When timer_sleep() is called the wake up time is calculated and stored
          in thread->time_to_wake and put_thread_to_sleep is called which changes 
          thread status to THREAD_BLOCKED and inserts it orderly into sleeping_list 
          and calls schedule().
  
          At each timer_tick call first few elements are whose wake_up_time <= timer_ticks 
          are put in ready list

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
  
          The insertion in sleeping list is done in ordered fashion and hence every timer_tick() 
          while poping elements, at max out we just need to check first few top elements of the queue, 
          and not all the queue.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
  
          When waking up the threads from the sleeping_list interrupt are disabled when we change thread status and put it into ready queue.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
  
          The other design that I thought of was to insert i



           PRIORITY SCHEDULER
           =================
-------DATA STRUCTURES-----

B1>>>>>>

Certain modifications are done to thread.h

Struct lock *lokw;

-The thread is waiting for which lock otherwise its value will be set to NULL.

Int init_priority;

- This is the basic priority of the thread

Struct list d_list;

- Thread will be having locks. So, which other threads are waiting on these locks are maintained in list which is decreasing order.

Struct list_elem d_list_elem

- The above list elements will be here. They will get added into d_list_elem

#define DEPTH_LIMIT 8

- This is to define the level limit for the lock

B2>>>>>>

Suppose there are 3 locks namely L1 L2 L3 and 4 threads namely A B C D .

L1

A->L3

B->C->D

L2

C d_list that is : A, B

D d_list that is: C

C lock_w:L3

D lock_w: NULL

C current donated priority: compare A B C , whoever have larger value

D donated priority: compare C and D, again whichever is larger

--------ALGORITHMS---------

B3>>>>>>>

There is list of waiters maintained which denotes the thread is waiting for the semaphores going to be up. This is mentioned in a semaphore. Thus, the list is sorted in decreasing order so, when waiters will be added they will make the starting thread with highest priority. This same list that is decreasing order sorted waiters list is maintained after semaphore is released.

There is basic concept considered like when high priority thread is getting added into the ready queue, then whatever will be the current running thread it will give cpu that means it should donate the cpu to the thread having high priority. As in we have considered above threads. Lets say there are 3 threads with high, medium and low priority, A, B, and C respectively. Lets consider how priority inversion problem happens. If the thread A is waiting for the lock, thread B is in the ready queue using cpu. So, thread A can not get the cpu or it can not execute. It just have one option to keep on waiting. This happens because, the C thread having low priority can not get the cpu , so B thread will be running first. Therefore, the problem is A’s priority is greater than the thread B, although thread B is running first. It uses next_thread_to _run to control the priority based scheduling.

What happens always is calling thread having maximum priority will execute first. Whenever it will call schedule it has to check the threads priority. In this situation, it has to call to the function test_produce().

Then, maintain the list of locks that is will store all the threads who will be waiting for locks. As soon as thread needed lock, it will call test_produce() in the beginning to test whether it has given first priority or not.

B4>>>>>>>

Let us consider how it work stepwise.

- First, the current thread sets the value of lockw variable to current lock. To avoid infinite loops due to thread causing deadlock, we have used depth level value as 8.

- Then the current thread includes itself to the d_list of lock holder.

- Priority will be donated again in certain number of steps like below mentioned:

  - thread = current thread

  - lock = current thread lockw

  - Until lock exists:

  - Check if there is any holder for lock, if no then return

  - If the lock holder’s priority is bigger than the current threads priority then return

  - Set thread’s priority into lock holders priority

  - Change the value of thread to lock holder

  - Finally update the lock with the value of lockw

B5>>>>>>>

- Initially we will set the value of lock holder to zero

- Then we will release threads waiting for recent released lock off the current threads d_list.

- Priority donation will be done once the lock is released

- Change the current threads priority where we will get max value of priority from d_list.

- Whoever thread having highest waiting priority will get the lock and will be put onto ready queue.

- Now there is a need to check if still current thread have max priority otherwise cpu will be given to that thread.

-

---------SYNCHRONIZATION---------

B6>>>>>>>

Current thread’s priority which gets updated on every 4 ticks in the interrupt handler that we are supposed to access it frequently. So, interrupt handler can not get the lock. Therefore, we can not use the lock. So, we have disabled interrupts like in thread_set_priority() function.

Race condition can be seen like, while the thread priority value is being changed to the new priority, interrupt handler is writing to the priority variable. Hence, conflicting writes will mess up the value of priority variable which leads to race condition.

---------RATIONALE-------------

B7>>>>>>

We have decided this design because, our first goal was to use least number of variables and less complex data structure to make things simple. Linked list we have used it to sort the list of locks and hence priorities which made it very easy and efficient. 

        ADVANCED SCHEDULER
        ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

              For struct thread in threads/thread.h:
                int8_t nice;                        
                          Niceness of thread (-20 to 20, 0 default)
                
                int recent_cpu;
                          Recent Usage of cpu

              For the threads/thread.c: 
                int load_avg;
                         Avg load of cpu from the previous second. It is 
                         accessible from everywhere and externed in thread.h


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     0   0   0   63  61  59     A 
 4     4   0   0   62  61  59     A 
 8     8   0   0   61  61  59     B 
12     8   4   0   61  60  59     A 
16     12  4   0   60  60  59     B 
20     12  8   0   60  59  59     A 
24     16  8   0   59  59  59     C 
28     16  8   4   59  59  58     B 
32     16  12  4   59  58  58     A 
36     20  12  4   58  58  58     C 

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
  
            Yes if two threads have equal priority then it does not say which one to
            run. So we run the one which has its priority changed most recently and 
            hence the last to be inserted in the queue.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
  
            The cost of scheduling inside the interrupt is more significant as compared to
            outside the interrupt especially corresponding to every fourth timer tick and 
            even more so on TIMER_FREQ ticks. The user threads would get lesser time to 
            execute every fourth timer tick but it is almost negligible otherwise.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

            The main advantage is that the design choices that we made is that 
            it makes use of systems inbuilt libraris and functionalities rather than making 
            everything from ground up.
            If we had extra time we could have implemented a heap and in a thread 
            list would be less expensive thereby.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
  
            We chose macros to implement the fixed point arithmetic. The reason we 
            did so is because its easier to implement(only a header file works no need 
            of .c file) and is optimized in the sense it does not call any function.

